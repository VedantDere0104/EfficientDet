{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EfficientDet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqO9OOrXv70c"
      },
      "source": [
        "####"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmzOU7hEv_IJ"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torchvision.transforms.functional as F\n",
        "import torch.nn.functional as f"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Maoayyy7uYM"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from torchvision.utils import make_grid\n",
        "from torchvision import transforms\n",
        "from tqdm.notebook import tqdm"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yku9CdTZwBTu"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HoGnaRWrjq53"
      },
      "source": [
        "def Reverse(lst):\n",
        "    return [ele for ele in reversed(lst)]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACBxQhi28CM8"
      },
      "source": [
        "def show_tensor_images(image_tensor):\n",
        "    size = (image_tensor.shape[1] , image_tensor.shape[2] , image_tensor.shape[3])\n",
        "    num_images = image_tensor.shape[0]\n",
        "    image_shifted = image_tensor\n",
        "    image_unflat = image_shifted.detach().cpu().view(-1, *size)\n",
        "    image_grid = make_grid(image_unflat[:num_images], nrow=5)\n",
        "    plt.imshow(image_grid.permute(1, 2, 0).squeeze())\n",
        "    plt.show()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaVsnI9x70KS"
      },
      "source": [
        "\n",
        "def iou_width_height(boxes1, boxes2):\n",
        "\n",
        "    intersection = torch.min(boxes1[..., 0], boxes2[..., 0]) * torch.min(\n",
        "        boxes1[..., 1], boxes2[..., 1]\n",
        "    )\n",
        "    union = (\n",
        "        boxes1[..., 0] * boxes1[..., 1] + boxes2[..., 0] * boxes2[..., 1] - intersection\n",
        "    )\n",
        "    return intersection / union"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2_Vp1Xb72Qr"
      },
      "source": [
        "def intersection_over_union(boxes_preds, boxes_labels, box_format=\"midpoint\"):\n",
        "\n",
        "    if box_format == \"midpoint\":\n",
        "        box1_x1 = boxes_preds[..., 0:1] - boxes_preds[..., 2:3] / 2\n",
        "        box1_y1 = boxes_preds[..., 1:2] - boxes_preds[..., 3:4] / 2\n",
        "        box1_x2 = boxes_preds[..., 0:1] + boxes_preds[..., 2:3] / 2\n",
        "        box1_y2 = boxes_preds[..., 1:2] + boxes_preds[..., 3:4] / 2\n",
        "        box2_x1 = boxes_labels[..., 0:1] - boxes_labels[..., 2:3] / 2\n",
        "        box2_y1 = boxes_labels[..., 1:2] - boxes_labels[..., 3:4] / 2\n",
        "        box2_x2 = boxes_labels[..., 0:1] + boxes_labels[..., 2:3] / 2\n",
        "        box2_y2 = boxes_labels[..., 1:2] + boxes_labels[..., 3:4] / 2\n",
        "\n",
        "    if box_format == \"corners\":\n",
        "        box1_x1 = boxes_preds[..., 0:1]\n",
        "        box1_y1 = boxes_preds[..., 1:2]\n",
        "        box1_x2 = boxes_preds[..., 2:3]\n",
        "        box1_y2 = boxes_preds[..., 3:4]\n",
        "        box2_x1 = boxes_labels[..., 0:1]\n",
        "        box2_y1 = boxes_labels[..., 1:2]\n",
        "        box2_x2 = boxes_labels[..., 2:3]\n",
        "        box2_y2 = boxes_labels[..., 3:4]\n",
        "\n",
        "    x1 = torch.max(box1_x1, box2_x1)\n",
        "    y1 = torch.max(box1_y1, box2_y1)\n",
        "    x2 = torch.min(box1_x2, box2_x2)\n",
        "    y2 = torch.min(box1_y2, box2_y2)\n",
        "\n",
        "    intersection = (x2 - x1).clamp(0) * (y2 - y1).clamp(0)\n",
        "    box1_area = abs((box1_x2 - box1_x1) * (box1_y2 - box1_y1))\n",
        "    box2_area = abs((box2_x2 - box2_x1) * (box2_y2 - box2_y1))\n",
        "\n",
        "    return intersection / (box1_area + box2_area - intersection + 1e-6)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0c9DY-twCxV"
      },
      "source": [
        "class Conv(nn.Module):\n",
        "    def __init__(self , \n",
        "                 in_channels , \n",
        "                 out_channels , \n",
        "                 kernel_size = (3 , 3) , \n",
        "                 stride = (1 , 1) , \n",
        "                 padding = 1 , \n",
        "                 use_norm = True , \n",
        "                 use_activation = True , \n",
        "                 use_grps = False):\n",
        "        super(Conv , self).__init__()\n",
        "\n",
        "        self.use_norm = use_norm\n",
        "        self.use_activation = use_activation\n",
        "        \n",
        "        groups = out_channels if use_grps else 1\n",
        "        self.conv1 = nn.Conv2d(in_channels , \n",
        "                               out_channels , \n",
        "                               kernel_size , \n",
        "                               stride , \n",
        "                               padding , \n",
        "                               groups = groups)\n",
        "        if self.use_norm:\n",
        "            self.norm = nn.BatchNorm2d(out_channels)\n",
        "        if self.use_activation:\n",
        "            self.relu = nn.ReLU6()\n",
        "\n",
        "    def forward(self , x):\n",
        "        x = self.conv1(x)\n",
        "        if self.use_norm:\n",
        "            x = self.norm(x)\n",
        "        if self.use_activation:\n",
        "            x = self.relu(x)\n",
        "        return x"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5Os81t3kUqS"
      },
      "source": [
        "class ConvT(nn.Module):\n",
        "    def __init__(self , \n",
        "                 in_channels , \n",
        "                 out_channels , \n",
        "                 kernel_size = (2 , 2) , \n",
        "                 stride = (2 , 2) , \n",
        "                 padding = 0 , \n",
        "                 use_norm = True , \n",
        "                 use_activation = True):\n",
        "        super(ConvT , self).__init__()\n",
        "\n",
        "        self.use_norm = use_norm\n",
        "        self.use_activation = use_activation\n",
        "\n",
        "        self.convT = nn.ConvTranspose2d(in_channels , \n",
        "                                        out_channels , \n",
        "                                        kernel_size , \n",
        "                                        stride ,\n",
        "                                        padding)\n",
        "        if self.use_norm:\n",
        "            self.norm = nn.InstanceNorm2d(out_channels)\n",
        "        if self.use_activation:\n",
        "            self.activation = nn.LeakyReLU(0.2)\n",
        "\n",
        "    def forward(self , x):\n",
        "        x = self.convT(x)\n",
        "        if self.use_norm:\n",
        "            x = self.norm(x)\n",
        "        if self.use_activation:\n",
        "            x = self.activation(x)\n",
        "        return x"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFS1gzNowEo4"
      },
      "source": [
        "class SqueezeExcitation(nn.Module):\n",
        "    def __init__(self , \n",
        "                 in_channels , \n",
        "                 out_channels):\n",
        "        super(SqueezeExcitation , self).__init__()\n",
        "\n",
        "        self.adp_avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.conv1 = Conv(in_channels , out_channels , kernel_size=(1 , 1) , padding=0)\n",
        "        self.silu = nn.SiLU()\n",
        "        self.conv2 = Conv(out_channels , in_channels , kernel_size=(1 , 1) , padding=0)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self , x):\n",
        "        x_ = x.clone()\n",
        "        x = self.adp_avg_pool(x)\n",
        "        x = self.conv1(x)\n",
        "        x = self.silu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.sigmoid(x)\n",
        "        x = x * x_\n",
        "        return x"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HR8LnbFGwH6-"
      },
      "source": [
        "class Inverted_Res_Block(nn.Module):\n",
        "    def __init__(self , \n",
        "                 in_channels , \n",
        "                 out_channels , \n",
        "                 t , \n",
        "                 padding , \n",
        "                 kernel_size , \n",
        "                 stride , \n",
        "                 reduction = 0.4 ,  \n",
        "                 ):\n",
        "        super(Inverted_Res_Block , self).__init__()\n",
        "        \n",
        "        self.use_residual = in_channels == out_channels and stride == 1\n",
        "        hidden_dim = in_channels * t\n",
        "        self.conv1 = Conv(in_channels , hidden_dim , kernel_size=(1 , 1) , stride=(1 , 1) , padding=0)\n",
        "        self.conv2 = Conv(hidden_dim , hidden_dim , kernel_size=kernel_size , stride=stride , use_grps=True , padding=padding)\n",
        "        self.conv3 = Conv(hidden_dim , out_channels , kernel_size=(1 , 1) , stride=(1 , 1) , padding=0)\n",
        "\n",
        "        reduced_dim = int(in_channels / reduction)\n",
        "        self.squeeze_excitation = SqueezeExcitation(out_channels , reduced_dim)\n",
        "\n",
        "    def forward(self , x):\n",
        "        x_ = x.clone()\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.squeeze_excitation(x)\n",
        "        if self.use_residual:\n",
        "            return x + x_\n",
        "        else :\n",
        "            return x"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q01WsDsXwKOY"
      },
      "source": [
        "\n",
        "config = [\n",
        "    # expand_ratio, channels, repeats, stride, kernel_size\n",
        "    [1, 16, 1, 1, 3],\n",
        "    'S' , \n",
        "    [6, 24, 2, 2, 3],\n",
        "    'S' , \n",
        "    [6, 40, 2, 2, 3],\n",
        "    'S' , \n",
        "    [6, 80, 3, 2, 3],\n",
        "    [6, 112, 3, 1, 3],\n",
        "    'S' , \n",
        "    [6, 192, 4, 2, 3],\n",
        "    [6, 320, 1, 1, 3],\n",
        "    'S'\n",
        "]\n",
        "\n",
        "phi_values = {\n",
        "    # tuple of: (phi_value, resolution, drop_rate)\n",
        "    \"b0\": (0, 512, 0.2),  \n",
        "    \"b1\": (0.5, 640, 0.2),\n",
        "    \"b2\": (1, 768, 0.3),\n",
        "    \"b3\": (2, 896, 0.3),\n",
        "    \"b4\": (3, 1024, 0.4),\n",
        "    \"b5\": (4, 1280, 0.4),\n",
        "    \"b6\": (5, 1280, 0.5),\n",
        "    \"b7\": (6, 1536, 0.5),\n",
        "}"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyKgmCTvw9jS"
      },
      "source": [
        "class Save_Block(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Save_Block , self).__init__()\n",
        "\n",
        "    def forward(self , x):\n",
        "        return x"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlZLLbS12wj9"
      },
      "source": [
        "class Efficient_Net(nn.Module):\n",
        "    def __init__(self , \n",
        "                 in_channels , \n",
        "                 version , \n",
        "                 out_channels_model , \n",
        "                 config=config, \n",
        "                 phi_values=phi_values):\n",
        "        super(Efficient_Net , self).__init__()\n",
        "\n",
        "        self.config=config\n",
        "        self.phi_values = phi_values\n",
        "        depth_factor , width_factor = self._get_scale_params(version)\n",
        "        out_channels = int(1280 * width_factor)\n",
        "\n",
        "        self.layers = self._get_layers(depth_factor , width_factor , out_channels)\n",
        "\n",
        "        self.cls = nn.Linear(out_channels , out_channels_model)\n",
        "        self.adp_avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "\n",
        "    def _get_layers(self , depth_factor , width_factor , out_channels_model):\n",
        "        layers = nn.ModuleList()\n",
        "        \n",
        "        channels = int(32 * width_factor)\n",
        "        layers.append(Conv(3 , channels , stride=(2 , 2)))\n",
        "        in_channels = channels\n",
        "        for layer in config:\n",
        "            if isinstance(layer , list):\n",
        "                t , out_channels , repeats , stride , kernel_size = layer\n",
        "                out_channels = 4 * int(int(out_channels * width_factor)/4)\n",
        "                repeats = int(repeats * depth_factor)\n",
        "\n",
        "                for repeat in range(repeats):\n",
        "                    layers.append(\n",
        "                        Inverted_Res_Block(\n",
        "                            in_channels , \n",
        "                            out_channels , \n",
        "                            t , \n",
        "                            stride = stride if repeat == 0 else 1 , \n",
        "                            kernel_size = kernel_size , \n",
        "                            padding = kernel_size // 2\n",
        "                        )\n",
        "                    )\n",
        "                    in_channels = out_channels\n",
        "            elif isinstance(layer , str):\n",
        "                layers.append(Save_Block())\n",
        "        layers.append(Conv(in_channels , out_channels_model , kernel_size=(1 , 1) , stride=(1 , 1) , padding=0))\n",
        "        return layers\n",
        "\n",
        "    def _get_scale_params(self , version , alpha=1.2 , beta=1.1):\n",
        "        phi_value , resolution , drop_rate = self.phi_values[version]\n",
        "        depth_factor = alpha ** phi_value\n",
        "        width_factor = beta ** phi_value\n",
        "        return depth_factor , width_factor\n",
        "\n",
        "    def forward(self , x):\n",
        "        x_out = []\n",
        "        for layer in self.layers:\n",
        "            if isinstance(layer , Save_Block):\n",
        "                x_out.append(x)\n",
        "            x = layer(x)\n",
        "            #print(x.shape)\n",
        "        return x_out"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByuY-mXPwOot"
      },
      "source": [
        "def test(version = 'b0'):\n",
        "    version = version\n",
        "    phi, res, drop_rate = phi_values[version]\n",
        "    num_examples, num_classes = 2, 10\n",
        "    x = torch.randn((num_examples, 3, res, res)).to(device)\n",
        "    model = Efficient_Net(\n",
        "        version=version,\n",
        "        out_channels_model=num_classes,\n",
        "        in_channels = 3\n",
        "    ).to(device)\n",
        "\n",
        "    x = model(x)\n",
        "    return x\n",
        "'''x = test()\n",
        "for x_ in x:\n",
        "    print(x_.shape)'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKEZq5GniY5L"
      },
      "source": [
        "in_channels_list_ = {\n",
        "    'b0': [16 , 24 , 40 , 112 , 320] , \n",
        "    'b1': [16 , 24 , 40 , 116 , 332] , \n",
        "    'b2': [16 , 24 , 44 , 120 , 352] , \n",
        "    'b3': [16 , 28 , 48 , 132 , 384] , \n",
        "    'b4': [20 , 28 , 52 , 148 , 424] , \n",
        "    'b5': [20 , 32 , 56 , 160 , 468] , \n",
        "    'b6': [24 , 36 , 64 , 180 , 512] , \n",
        "    'b7': [28 , 40 , 68 , 196 , 564]    \n",
        "}"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlmwqtocxqWa"
      },
      "source": [
        "class BiFPN_Layer(nn.Module):\n",
        "    def __init__(self , \n",
        "                 in_channels_list = [2048 , 1024 , 512 , 256 , 128] , \n",
        "                 out_channels = [128 , 256 , 512 , 1024 , 2048]):\n",
        "        super(BiFPN_Layer , self).__init__()\n",
        "\n",
        "        self.top_down = nn.ModuleList()\n",
        "        self.bottom_up = nn.ModuleList()\n",
        "\n",
        "        j = 0\n",
        "        for i , channels in enumerate(in_channels_list):\n",
        "            if i == 0 or i == len(in_channels_list)-1:\n",
        "                if i == 0:\n",
        "                    self.top_down.append(Conv(channels , in_channels_list[i+1] , stride=(2 , 2)))\n",
        "            else :\n",
        "                self.top_down.append(Conv(channels * 2 , in_channels_list[i+1] , stride=(2 , 2)))\n",
        "        \n",
        "        reversed_in_channels_list = Reverse(in_channels_list)\n",
        "\n",
        "        for i , channels in enumerate(reversed_in_channels_list):\n",
        "            if i == 0 or i == len(reversed_in_channels_list) -1 :\n",
        "                if i == 0:\n",
        "                    self.bottom_up.append(ConvT(channels*2 , out_channels[i]))\n",
        "                else :\n",
        "                    self.bottom_up.append(ConvT(channels + out_channels[i-1] , out_channels[i]))\n",
        "            else :\n",
        "                self.bottom_up.append(ConvT(channels * 2 + out_channels[i-1] , out_channels[i]))\n",
        "    \n",
        "    def forward(self , x):\n",
        "        x_1 = []\n",
        "        x_out = []\n",
        "        j = 0\n",
        "        for i , x_ in enumerate(x):\n",
        "          \n",
        "            if i == 0 or i == len(x)-1:\n",
        "                if i == 0:\n",
        "                    x_1.append(self.top_down[j](x_))\n",
        "                    j += 1\n",
        "                elif i == len(x) - 1:\n",
        "                    lamp = 0\n",
        "            else :\n",
        "                #print(x[i].shape , x_1[-1].shape)\n",
        "                temp = torch.cat([x[i] , x_1[-1]] , dim=1)\n",
        "                x_1.append(self.top_down[j](temp))\n",
        "                j+=1\n",
        "        x_1_reversed = Reverse(x_1)\n",
        "        x_reversed = Reverse(x)\n",
        "        j = 0\n",
        "        for i in range(len(x)):\n",
        "            if i == 0 or i == len(x) - 1:\n",
        "                if i == 0:\n",
        "                    temp = torch.cat([x_reversed[i] , x_1_reversed[i]] , dim=1)\n",
        "                    x_out.append(self.bottom_up[j](temp))\n",
        "                    j += 1\n",
        "                else :\n",
        "                    temp = torch.cat([x_reversed[-1] , x_out[-1]] , dim=1)\n",
        "                    x_out.append(self.bottom_up[j](temp))\n",
        "            else :\n",
        "                #print(x_out[-1].shape)\n",
        "                x_out[-1] = F.resize(x_out[-1] , (x_1_reversed[i].shape[2] , x_1_reversed[i].shape[2]))\n",
        "                #print(x_reversed[i].shape , x_1_reversed[i].shape , x_out[-1].shape)\n",
        "                temp = torch.cat([x_reversed[i] , x_1_reversed[i] , x_out[-1]] , dim=1)\n",
        "                x_out.append(self.bottom_up[j](temp))\n",
        "                j += 1\n",
        "        return x_out"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQh3SwN1jfdC"
      },
      "source": [
        "'''version = 'b0'\n",
        "bifpn = BiFPN_Layer(in_channels_list_[version] , \n",
        "                    Reverse(in_channels_list_[version]))\n",
        "x = test(version = version)\n",
        "z = bifpn(x)\n",
        "for z_ in z:\n",
        "    print(z_.shape)'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIGAXoSjrlrW"
      },
      "source": [
        "class Repeated_BiFPN(nn.Module):\n",
        "    def __init__(self , \n",
        "                 version , \n",
        "                 in_channels_list = [2048 , 1024 , 512 , 256 , 128] ,\n",
        "                 out_channels_list_model = [128 , 256 , 512 , 1024 , 2048]):\n",
        "        super(Repeated_BiFPN , self).__init__()\n",
        "\n",
        "        version_list = {\n",
        "            'b0':0 , \n",
        "            'b1':1 , \n",
        "            'b2':2 , \n",
        "            'b3':3 , \n",
        "            'b4':4 , \n",
        "            'b5':5 , \n",
        "            'b6':6 , \n",
        "            'b7':7\n",
        "        }\n",
        "\n",
        "        phi = version_list[version]\n",
        "        \n",
        "        repeats = 1 + phi\n",
        "        \n",
        "        out_channels_list = self._get_out_channels(in_channels_list , phi)\n",
        "\n",
        "        self.layers = nn.ModuleList()\n",
        "\n",
        "        for i , repeat in enumerate(range(repeats)):\n",
        "            if i == repeats - 1:\n",
        "                out_channels_list = out_channels_list_model\n",
        "            self.layers.append(\n",
        "                BiFPN_Layer(in_channels_list , out_channels_list)\n",
        "            )\n",
        "            in_channels_list = out_channels_list\n",
        "\n",
        "\n",
        "    def _get_out_channels(self , in_channels_list , phi):\n",
        "        out_channels_list_ = []\n",
        "        out_channels_coe = 64 * 1.35 ** phi\n",
        "        for channels in in_channels_list:\n",
        "            out_channels_list_.append(\n",
        "                int(channels * out_channels_coe)\n",
        "            )\n",
        "        return out_channels_list_\n",
        "\n",
        "    def forward(self , x):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        return x"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpB7mCI--UTd"
      },
      "source": [
        "'''version = 'b0'\n",
        "repeated_bifpn = Repeated_BiFPN(version , \n",
        "                                in_channels_list=in_channels_list_[version]).to(device)\n",
        "x = test(version = version)\n",
        "z = repeated_bifpn(x)\n",
        "for z_ in z:\n",
        "    print(z_.shape)'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KR5h7UsH_xUr"
      },
      "source": [
        "class EfficientDet(nn.Module):\n",
        "    def __init__(self ,  \n",
        "                 version , \n",
        "                 in_channels_list_ = in_channels_list_):\n",
        "        super(EfficientDet , self).__init__()\n",
        "\n",
        "        self.efficientnet = Efficient_Net(3 , version , out_channels_model=10)\n",
        "        self.repeated_bifpn = Repeated_BiFPN(version , \n",
        "                                             in_channels_list = in_channels_list_[version] , \n",
        "                                             out_channels_list_model=[128 , 128 , 128 , 128 , 128])\n",
        "\n",
        "    def _get_sum(self , x):\n",
        "        x_out = 0\n",
        "        for i , x_ in enumerate(x):\n",
        "            x[i] = f.adaptive_avg_pool2d(x_ , (13 , 13))\n",
        "            x_out += x[i]\n",
        "        return x_out\n",
        "\n",
        "    def forward(self , x):\n",
        "        x = self.efficientnet(x)\n",
        "        x = self.repeated_bifpn(x)\n",
        "        x = self._get_sum(x)\n",
        "        return x"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IvIcxnTtLDU4"
      },
      "source": [
        "'''def test_model(version):\n",
        "    phi , res , drop_rate = phi_values[version]\n",
        "    num_examples = 2\n",
        "    x = torch.randn((num_examples , 3 , res , res)).to(device)\n",
        "    efficientdet = EfficientDet(version)\n",
        "    x = efficientdet(x)\n",
        "    print(x.shape)'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aym7qF08Rrhy"
      },
      "source": [
        "#test_model('b0')"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eS1drjnZRtSu"
      },
      "source": [
        "class Pred(nn.Module):\n",
        "    def __init__(self ,\n",
        "                 version , \n",
        "                 in_channels = 128 , \n",
        "                 num_classes = 20 , \n",
        "                 B = 5 ,\n",
        "                 S = 13):\n",
        "        super(Pred , self).__init__()\n",
        "\n",
        "        self.layers = nn.ModuleList()\n",
        "        out_classes = num_classes + 4\n",
        "        out_channels_model = out_classes * B\n",
        "\n",
        "        version_list = {\n",
        "            'b0':0 , \n",
        "            'b1':1 , \n",
        "            'b2':2 , \n",
        "            'b3':3 , \n",
        "            'b4':4 , \n",
        "            'b5':5 , \n",
        "            'b6':6 , \n",
        "            'b7':7\n",
        "        }\n",
        "        phi = version_list[version]\n",
        "\n",
        "        repeats = int(3 + phi // 3)\n",
        "        out_channels_coe = 64 * 1.35 ** phi\n",
        "        out_channels = int(in_channels * out_channels_coe)\n",
        "\n",
        "        for repeat in range(repeats):\n",
        "            if repeat == repeats - 1:\n",
        "                out_channels = out_channels_model\n",
        "            \n",
        "            self.layers.append(\n",
        "                Conv(in_channels , out_channels)\n",
        "            )\n",
        "            in_channels = out_channels\n",
        "\n",
        "    def forward(self , x):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        return x"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OX6EccRXtuBw"
      },
      "source": [
        "'''x = torch.randn((2 , 128 , 13 , 13)).to(device)\n",
        "pred = Pred('b0')\n",
        "z = pred(x)\n",
        "#print(z.shape)\n",
        "z = z.view(z.shape[0] , 5 , 13 , 13 , 24)\n",
        "print(z.shape)'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaL4Df2X01oZ"
      },
      "source": [
        "class EfficientDet_Model(nn.Module):\n",
        "    def __init__(self , \n",
        "                 version , \n",
        "                 B = 5 , \n",
        "                 C = 20 , \n",
        "                 S = 13):\n",
        "        super(EfficientDet_Model , self).__init__()\n",
        "\n",
        "        self.efficientdet = EfficientDet(version)\n",
        "        self.pred = Pred(version)\n",
        "\n",
        "        self.B = B\n",
        "        self.C = C\n",
        "        self.S = S\n",
        "\n",
        "    def forward(self , x):\n",
        "        x = self.efficientdet(x)\n",
        "        x = self.pred(x)\n",
        "        return x.view(x.shape[0] , self.B , self.S , self.S , self.C + 4)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "001aQZ6V5Afb"
      },
      "source": [
        "def test_model(version):\n",
        "    phi , res , drop_rate = phi_values[version]\n",
        "    num_examples = 2\n",
        "    x = torch.randn((num_examples , 3 , res , res)).to(device)\n",
        "    efficientdet = EfficientDet_Model(version)\n",
        "    x = efficientdet(x)\n",
        "    print(x.shape)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1iBsQ5S5GgZ"
      },
      "source": [
        "#test_model(\"b0\")"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVl2vahr5HJR"
      },
      "source": [
        "class Dataset_(torch.utils.data.Dataset):\n",
        "    def __init__(self ,\n",
        "                 img_dir , \n",
        "                 label_dir , \n",
        "                 csv_file , \n",
        "                 anchors , \n",
        "                 S = 13 , \n",
        "                 B = 5 , \n",
        "                 C = 20 , \n",
        "                 version = 'b0' , \n",
        "                 phi_values = phi_values):\n",
        "        super(Dataset_ , self).__init__()\n",
        "\n",
        "        self.img_dir = img_dir\n",
        "        self.label_dir = label_dir\n",
        "        self.df = pd.read_csv(csv_file)\n",
        "        self.anchors = torch.from_numpy(np.array(anchors))\n",
        "        #print(self.anchors)\n",
        "        self.number_of_anchors_per_cell = 5\n",
        "        self.ignore_iou_thresh = 0.5\n",
        "        self.C = C\n",
        "        self.S = S\n",
        "        self.B = B\n",
        "        phi , res , _ = phi_values[version]\n",
        "\n",
        "        res = res\n",
        "\n",
        "        self.transforms = transforms.Compose([\n",
        "                                        transforms.ToPILImage() , \n",
        "                                        transforms.Resize((res , res)) , \n",
        "                                        transforms.ToTensor()\n",
        "        ])\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    \n",
        "    def __getitem__(self , idx):\n",
        "        label_path = os.path.join(self.label_dir , self.df.iloc[idx , 1])\n",
        "        boxes = []\n",
        "\n",
        "        with open(label_path) as f:\n",
        "            for label in f.readlines():\n",
        "                class_label , x , y , width , height = [\n",
        "                    float(x) if float(x) != int(float(x)) else int(x)\n",
        "                    for x in label.replace(\"\\n\", \"\").split()\n",
        "                ]\n",
        "                boxes.append([ x , y , width , height , class_label])\n",
        "\n",
        "        boxes = torch.tensor(boxes) \n",
        "\n",
        "        img_path = os.path.join(self.img_dir , self.df.iloc[idx , 0])\n",
        "        image = np.asarray(plt.imread(img_path))\n",
        "        image = torch.from_numpy(image).permute(2 , 0 , 1)\n",
        "        if self.transforms:\n",
        "            image = self.transforms(image)\n",
        "\n",
        "        targets = torch.zeros((self.B , self.S , self.S , 6))\n",
        "        for box in boxes:\n",
        "            iou_anchors = iou_width_height(box[2:4] , self.anchors)\n",
        "            anchors_indices = iou_anchors.argsort(descending=True, dim=0)        \n",
        "            x , y , width , height , class_label = box\n",
        "            has_anchor = [False for _ in range(self.B)]\n",
        "            for anchor_idx in anchors_indices:\n",
        "                anchor_on_scale = anchor_idx % self.B\n",
        "                S = self.S\n",
        "                i , j = int(S * y) , int(S * x)\n",
        "                anchor_taken = targets[anchor_on_scale , i , j , 0]\n",
        "                if not anchor_taken and not has_anchor[anchor_on_scale]:\n",
        "                    targets[anchor_on_scale , i , j , 0] = 1\n",
        "                    x_cell , y_cell = S * x - j , S * y - i\n",
        "                    width_cell , height_cell = (\n",
        "                        width * S , \n",
        "                        height * S\n",
        "                    )\n",
        "                    box_coordinate = torch.tensor([x_cell , y_cell , width_cell , height_cell])\n",
        "                    targets[anchor_on_scale , i , j , 1:5] = box_coordinate\n",
        "                    targets[anchor_on_scale , i , j , 5] = int(class_label)\n",
        "                    has_anchor[anchor_on_scale] = True\n",
        "\n",
        "                elif not anchor_taken and iou_anchors[anchor_idx] > self.ignore_iou_thresh:\n",
        "                    targets[anchor_on_scale , i , j , 0] = -1\n",
        "        return image , targets"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCAMzcjP7pS6"
      },
      "source": [
        "anchors = [[ 0.28, 0.22], [  0.38, 0.48], [ 0.9, 0.78], [ 0.07, 0.15], [ 0.15, 0.11]]\n",
        "dataset = Dataset_(\n",
        "    img_dir = '/content/drive/MyDrive/Yolo_Dataset/images/' , \n",
        "    label_dir = '/content/drive/MyDrive/Yolo_Dataset/labels' , \n",
        "    csv_file = '/content/drive/MyDrive/Yolo_Dataset/train.csv' , \n",
        "    anchors = anchors \n",
        ")\n",
        "dataloader = torch.utils.data.DataLoader(dataset , batch_size = 2 , shuffle=True)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZYSJ3Nw7rH0"
      },
      "source": [
        "for x , y in dataloader:\n",
        "    show_tensor_images(x)\n",
        "    print(x.shape)\n",
        "    print(y.shape)\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQMsuURm8EMj"
      },
      "source": [
        "class Loss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Loss , self).__init__()\n",
        "\n",
        "        self.mse = nn.MSELoss()\n",
        "        self.en = nn.CrossEntropyLoss()\n",
        "        self.bce = nn.BCEWithLogitsLoss()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "\n",
        "        self.lambda_class = 1\n",
        "        self.lambda_noobj = 10\n",
        "        self.lambda_obj = 1\n",
        "        self.lambda_box = 10\n",
        "\n",
        "    def forward(self , predictions , targets , anchors):\n",
        "        anchors = torch.tensor(anchors)\n",
        "        obj = targets[... , 0] == 1\n",
        "        noobj = targets[... , 0] == 0\n",
        "\n",
        "        no_obj_loss = self.mse(\n",
        "            (predictions[... , 0:1][noobj]) , (targets[... , 0:1][noobj])\n",
        "        )\n",
        "\n",
        "        anchors = anchors.reshape(1 , 5 , 1 , 1 , 2)\n",
        "        box_preds = torch.cat([self.sigmoid(predictions[... , 1:3]) , torch.exp(predictions[... , 3:5]) * anchors] , dim = -1)\n",
        "        ious = intersection_over_union(box_preds[obj] , targets[... , 1:5][obj]).detach()\n",
        "        object_loss = self.mse(self.sigmoid(predictions[... , 0:1][obj]) , ious * targets[... , 0:1][obj])\n",
        "\n",
        "        predictions[... , 1:3] = self.sigmoid(predictions[... , 1:3])\n",
        "        targets[..., 3:5] = torch.log(\n",
        "            (1e-16 + targets[..., 3:5] / anchors)\n",
        "        )  \n",
        "        box_loss = self.mse(predictions[... , 1:5][obj] , targets[... , 1:5][obj])\n",
        "\n",
        "        class_loss = self.en(\n",
        "            (predictions[... , 5:][obj]) , (targets[... , 5][obj].long())\n",
        "        )\n",
        "\n",
        "        return (\n",
        "            self.lambda_box * box_loss\n",
        "            + self.lambda_obj * object_loss\n",
        "            + self.lambda_noobj * no_obj_loss\n",
        "            + self.lambda_class * class_loss\n",
        "        )"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRcLVAYE8Lpj"
      },
      "source": [
        "'''version = 'b0'\n",
        "loss_ = Loss().to(device)\n",
        "efficientdet = EfficientDet_Model(version)\n",
        "phi , res , _ = phi_values[version]\n",
        "for x , y in dataloader:\n",
        "    predictions = efficientdet(x)\n",
        "    break\n",
        "z = loss_(predictions , y , anchors)'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3VFAs-zAHxT"
      },
      "source": [
        "version = 'b0'\n",
        "efficientdet = EfficientDet_Model(version).to(device)\n",
        "loss_ = Loss().to(device)\n",
        "lr = 0.002\n",
        "betas = (0.5 , 0.999)\n",
        "opt = torch.optim.Adam(efficientdet.parameters() , lr=lr , betas = betas)\n",
        "epochs = 200\n",
        "display_steps = 100"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xp1JhVzAAVi9"
      },
      "source": [
        "def train():\n",
        "    mean_loss = 0\n",
        "    cur_step = 0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        for x , y in tqdm(dataloader):\n",
        "            x , y = x.to(device) , y.to(device)\n",
        "\n",
        "            opt.zero_grad()\n",
        "            y_ = efficientdet(x)\n",
        "            loss = loss_(y_ , y , anchors)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            \n",
        "            mean_loss += loss.item() / display_steps\n",
        "            if cur_step % display_steps == 0:\n",
        "                print(f'Epoch {epoch} , Step {cur_step} , Mean YOLO Loss {mean_yolo_loss}')\n",
        "            cur_step +=1\n",
        "        mean_loss = 0"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-99BC6REAj4j"
      },
      "source": [
        "train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-omxtTWnA02N"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}